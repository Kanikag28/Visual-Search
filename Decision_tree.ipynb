{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree Algorithm\n",
    "A  decision tree has a tree structure with decision nodes and the leaf nodes. The decision nodes check a condition and then further branches out whereas the leaf nodes are the final outcomes. \n",
    "\n",
    "There are both Regression Decision trees and Classification Decision Trees, which are used when the dependent variable is continuous and categorical respectively.<br>\n",
    "In Regression Tree, the prediction made by the leaf node is the mean of all observations falling in that region , where as it is the mode in case of Classificatiom Trees.\n",
    "\n",
    "## 1. Regression Decision Tree:\n",
    "\n",
    "### Step 1 - Create a Gini Index.\n",
    "Gini Index is the name of cost function(loss function) to evaluate the splits. Splits are nothing but division of the decision node in further sub nodes.\n",
    "\n",
    "Conditions for Gini Index:\n",
    "- It works with Categorical Target Variable.\n",
    "- It performs only Binary splits ( i.e. divide into two sub-nodes ) \n",
    "\n",
    "Git score tells you how good the split is by how mixed the classes are in the two groups created by the split. (groups = sub-nodes). If gini score is 0 , that means the split is perfect and the samples in each group belong to same class. The worst case is when both group contains all the possible classes, where gini score is 0.5.\n",
    "\n",
    "To calculate Gini index:\n",
    "- Calculate the proportion of classes in each group .\n",
    "proportion = $ \\frac{no. of class-value}{no. of rows} $ <br>\n",
    "For example;we have two groups - group1 belonging to class 0 and group2 belonging to class 1, both containing 2 rows.<br>\n",
    "proportion for:\n",
    "       - group_1_class_0 = 2 / 2 = 1\n",
    "       - group_1_class_1 = 0 / 2 = 0\n",
    "       - group_2_class_0 = 0 / 2 = 0\n",
    "       - group_2_class_1 = 2 / 2 = 1\n",
    "- Then we calculate gini_index for each child node.\n",
    "gini_index = 1.0 - sum(proportion * proportion)\n",
    "- Then we calculate gini_index for each group by the size of the group, relative to all of the samples in the parent. Samples = total no of rows including all groups.\n",
    "gini_index = (1.0 - sum(proportion * proportion)) * (group_size/total_samples)\n",
    "\n",
    "Example; gini_index for :\n",
    "        - Gini(group_1) = (1 - (1*1 + 0*0)) * 2/4 = 0.0\n",
    "        - Gini(group_2) = (1 - (0*0 + 1*1)) * 2/4 = 0.0\n",
    "- Then we calculate Gini Score, which is equal to sum of ginit_index of both groups. \n",
    "gini_score = Gini(group_1) + Gini(group_2)\n",
    "\n",
    "For example; In above case\n",
    "gini_score = 0 , which is perfect split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create a Split.\n",
    "This means to find the index of the attribute that needs to be split and the value by which to split samples(rows) on that attribute.\n",
    "It contains two steps:\n",
    "- Splitting a Dataset\n",
    "- Evaluating all splits\n",
    "\n",
    "### Splitting a Dataset.\n",
    "It means to split the rows of the dataset given the index of attribute and the split value for that attribute.<br>\n",
    "It is done by iterating over each row and checking if attribute value is less or more than the split value and assigning it in left or right group respectively.<br>\n",
    "Left group has rows whose attribute value is less than the split value.<br>\n",
    "Right group has rows whose attribute value is more than or equal to the split value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Split.\n",
    "In a given dataset, we have to check each value on every attribute as a candidate split and then evaluate the cost of each split and get the best possible split.<br>\n",
    "The best split is then used as a node in the decision tree.\n",
    "\n",
    "To find best split, what we do is : <br>\n",
    "Create a dictionary by the key as a split number and value as the list of the index of the chosen attribute, the value of that attribute by which to split and the two groups of data split by the chosen split point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index + 1, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 1, 'value': 6.642287351, 'groups': ([[2.771244718, 1.784783929, 0], [1.728571309, 1.169761413, 0], [3.678319846, 2.81281357, 0], [3.961043357, 2.61995032, 0], [2.999208922, 2.209014212, 0]], [[7.497545867, 3.162953546, 1], [9.00220326, 3.339047188, 1], [7.444542326, 0.476683375, 1], [10.12493903, 3.234550982, 1], [6.642287351, 3.319983761, 1]])}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "split = get_split(dataset)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Build a Tree.\n",
    "To build a tree, we need to add many nodes in a specific manner.<br>\n",
    "It is divided in 3 parts :\n",
    "- Terminal Nodes.\n",
    "- Recursive Splitting.\n",
    "- Building a Tree.\n",
    "\n",
    "### Terminal Nodes\n",
    "Terminal nodes are the leaf nodes. In this part , we decide when to stop growing the tree.<br>\n",
    "That can be done by using the depth and the number of rows that the node is responsible for in the training dataset. <br>\n",
    "- Maximum Tree Depth:\n",
    "This means maximum number of nodes from the root node. Once we get the maximum get , we must stop adding new nodes.\n",
    "- Minimum Node Records:\n",
    "This means minimum number of samples that a given node is responsible for. Once at or below this minimum, we must stop splitting and adding new nodes.<br>\n",
    "One more approach is to decide when the split at node will belong to one group only, which is possible . By this we will be unable to split the node further and it will become a terminal node which will be used for final prediction.\n",
    "\n",
    "Final prediction will be made by taking the group of rows assigned to that node and selecting the most common class value in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Splitting\n",
    "When we split a node , our dataset gets divided into groups. For further nodes we have to call __get_split__ function again for the new groups.<br>\n",
    "The new nodes added to a node are called child nodes of that node. a node may contain zero children(if it is a terminal node)b , 1 child( if one side makes a prediction directly ) and 2 children ( left and right child ). \n",
    "\n",
    "This part defines a function which controls when to stop calling the __get_split__ function, i.e. when to stop adding nodes.\n",
    "\n",
    "The argumnents for this function are - node, maximum depth, minimum number of samples in a node and the current depth of a node.\n",
    "\n",
    "steps to do it:\n",
    "- First we split our datastet(root node) into left and right group and then delete the groups from that node, so that we can store new groups in the variable.\n",
    "- Then we check if either left or right group of rows is empty and if so we create a terminal node using what records we do have.\n",
    "- Then we check if we reached our maximum depth and if so we create terminal node.\n",
    "- Then we check for left child, if it has rows less than the minimum size , we create it a terminal node. Otherwise we do the same procedures from step 1 and increase depth by 1.\n",
    "- Then we do the same process on right child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Tree\n",
    "To build a tree , first step is to split the training data and then call recursive splitting function.<br>\n",
    "And then to print the tree, we recursively print out nodes of the decision tree with one line per node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):  # isinstance() function returns True if the specified object is of the specified type, otherwise False\n",
    "    # It will check if the node is dictionary or not.\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']), node['value'])))\n",
    "        #Depth*' ' is used for right indenting to show each node and it's child nodes. \n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "        # when the node will become terminal node , it will be integer and then else statement will be executed.\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 < 6.642]\n",
      " [X1 < 2.771]\n",
      "  [0]\n",
      "  [X1 < 2.771]\n",
      "   [0]\n",
      "   [0]\n",
      " [X1 < 7.498]\n",
      "  [1]\n",
      "  [X1 < 7.498]\n",
      "   [1]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(dataset, 5, 2)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain the following output as a tree. <br>\n",
    "`[X1 < 6.642]    # root node (A) \n",
    " [X1 < 2.771]    # Left child node of A (P)\n",
    "  [0]            # Left Terminal child node of P with outcome as 0\n",
    "  [X1 < 2.771]   # Right child node of P (X)\n",
    "   [0]           # Left terminal child node of X\n",
    "   [0]           # Right terminal child node of X\n",
    " [X1 < 7.498]    # Right child node of A (Q) \n",
    "  [1]            # Left terminal child node of Q\n",
    "  [X1 < 7.498]   # Right child node of Q (Y)\n",
    "   [1]           # Left terminal child node of Y\n",
    "   [1]           # Right terminal child node of Y.\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Making a Prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
    "for row in dataset:\n",
    "\tprediction = predict(stump, row)\n",
    "\tprint('Expected=%d, Got=%d' % (row[-1], prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
