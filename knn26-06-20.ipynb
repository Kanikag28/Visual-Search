{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Search from Scratch\n",
    "\n",
    "## 1st Step is to calculate Euclidean Distance.\n",
    "We calculate euclidean distance between the two rows in dataset.\n",
    "\n",
    "Euclidean distance = sqrt((x2-x1)^2 + (y2-y1)^2 + (z2-z1)^2 + ....)\n",
    "\n",
    "In the test dataset provided below the first two columns are the input variables and the last column is the output which gives label as it is categorised in 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.850940186986411\n",
      "2.592833759950511\n",
      "4.214227042632867\n",
      "6.522409988228337\n",
      "4.985585382449795\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return math.sqrt(distance)\n",
    "# Taking a testing data to get the output:\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "# Finding Euclidean Distance of every row from first row\n",
    "for row in dataset:\n",
    "    distance = euclidean_distance(dataset[0], row)\n",
    "    print(distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Step is to get Nearest Neighbors.\n",
    "After calculating distance, you can find the 'K' nearest neighbors which will have the least distance from the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n",
      "[3.06407232, 3.005305973, 0]\n",
      "[1.465489372, 2.362125076, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_neighbors(train, test_row, k):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "neighbors = get_neighbors(dataset, dataset[0], 3)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in above code, first it will calculate the distance of each row from the train_row. And then add the train_row and it's distance as tuple  in the distances list. Then we sort the list __distances__ in ascending order , \"key = lambda tup:tup[1] \" means the key = the element at position 1 of the tuple ,i.e. distance. So the list distances get sorted in ascending order by distance.\n",
    "\n",
    "After this , we will add all the trainrow of first \"K\" elements in the neighbors list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 is Making Predictions\n",
    "After getting the most similar neighbors , we will make predictions.\n",
    "In the case of classification, we can return the most represented class among the neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 0, Got 0.\n"
     ]
    }
   ],
   "source": [
    "def predict_classification(train, test_row, k):\n",
    "    neighbors = get_neighbors(train, test_row, k)\n",
    "    output_values = [row[-1] for row in neighbors] \n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "prediction = predict_classification(dataset, dataset[0], 3)\n",
    "print('Expected %d, Got %d.' % (dataset[0][-1], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, output values store the last value of each row in the neighbors list.\n",
    "Then predicition finds the max value used in the set __output_values__ by counting the frequency of each number.\n",
    "\n",
    "Then in last we print the actual value(Expected) and the predicted value(Got)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Search on Images:\n",
    "\n",
    "To do KNN Search in Visual Search, we'll first use a pretrained CNN model and do the feature extraction and then KNN Search.\n",
    "\n",
    "A CNN model ( CONVOLUTIONAL NEURAL NETWORK ) is a type of deep learning which is applied to analyze visual imagery. They are applied in images recognition, images classifications , objects detections, recognition faces etc.\n",
    "\n",
    "So here we'll use a pretrained model based on RestNet architecture from MXNet Model Zoo.\n",
    "\n",
    "MXNet is a powerful open-source deep learning instrument built to ease the development of deep learning algorithms. It is used to define, train and deploy deep neural networks and allows fast model-training and supports a flexible programming model.\n",
    "\n",
    "Model_zoo is a package which provides pre-defined and pre-trained models to help in ML algorithms.\n",
    "\n",
    "RestNet architecture has achieved high accuracy in classifying the over 11 million images of the ImageNet dataset.\n",
    "There are also many other architectures available like alexnet , squeezenet ,densenet etc.\n",
    "\n",
    "This modelâ€™s output layer generates feature vectors instead of labels for classifying images.Feature vectors are one of the core components of visual search.\n",
    "\n",
    "For KNN Search: \n",
    "First step is to construct an index. By the index we can look up for \"neighbors\" by the Euclidean distance or cosine similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hnswlib in /home/kanika/anaconda3/lib/python3.7/site-packages (0.3.4)\n",
      "Requirement already satisfied: pybind11>=2.0 in /home/kanika/anaconda3/lib/python3.7/site-packages (from hnswlib) (2.5.0)\n",
      "Requirement already satisfied: numpy in /home/kanika/anaconda3/lib/python3.7/site-packages (from hnswlib) (1.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__hnswlib__ is a library which provides many functions for approximate nearest neighbor search. It uses an efficient and totally graph-based approach.\n",
    "\n",
    "So, first we'll create the index.\n",
    "\n",
    "`num_elements = len(features)\n",
    "labels_index = np.arange(num_elements)`\n",
    "\n",
    "num_elements will store the length of features vector and then label_index will create a numpy array of range (0 to (num_elements - 1)).\n",
    "\n",
    "`p = hnswlib.Index(space = 'cosine', dim = EMBEDDING_SIZE)`\n",
    "__hnswlib.Index__ will help to create an non- initialized index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
